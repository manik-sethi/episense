{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import pyedflib\n",
    "import io\n",
    "import tempfile\n",
    "import s3fs\n",
    "from dotenv import dotenv_values, load_dotenv\n",
    "from extraction import extract_interictal_preictal\n",
    "from pipeline import Pipeline\n",
    "import os\n",
    "\n",
    "load_dotenv()  # This will load variables from .env into os.environ\n",
    "\n",
    "api_key = os.getenv(\"aws_access_key_id\")\n",
    "secret_key = os.getenv(\"aws_secret_access_key\")\n",
    "region = os.getenv(\"region_name\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating AWS Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_variables = dotenv_values(\".env\")  # Reads local .env if it exists\n",
    "\n",
    "api_key = env_variables.get(\"aws_access_key_id\") or os.getenv(\"aws_access_key_id\")\n",
    "secret_key = env_variables.get(\"aws_secret_access_key\") or os.getenv(\"aws_secret_access_key\")\n",
    "region = env_variables.get(\"region_name\") or os.getenv(\"region_name\")\n",
    "\n",
    "session = boto3.Session(\n",
    "    aws_access_key_id=api_key,\n",
    "    aws_secret_access_key=secret_key,\n",
    "    region_name=region\n",
    ")\n",
    "\n",
    "fs = s3fs.S3FileSystem(\n",
    "    key=api_key,\n",
    "    secret=secret_key,\n",
    "    client_kwargs={'region_name': region}\n",
    ")\n",
    "s3 = session.client(\"s3\")\n",
    "\n",
    "bucket_name = \"maniks-chb-mit\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading in Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "def load_config(config_path):\n",
    "    with open(config_path, 'r') as f:\n",
    "        config = yaml.safe_load(f)\n",
    "    return config\n",
    "\n",
    "# Load configuration from config.yaml\n",
    "config = load_config(\"config.yaml\")\n",
    "subject_list = config[\"subject_range\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['chb01/chb01-summary.txt', 'chb02/chb02-summary.txt', 'chb03/chb03-summary.txt', 'chb05/chb05-summary.txt', 'chb08/chb08-summary.txt', 'chb09/chb09-summary.txt', 'chb10/chb10-summary.txt', 'chb14/chb14-summary.txt', 'chb16/chb16-summary.txt', 'chb17/chb17-summary.txt', 'chb20/chb20-summary.txt', 'chb21/chb21-summary.txt', 'chb23/chb23-summary.txt']\n"
     ]
    }
   ],
   "source": [
    "print(summs)\n",
    "baka = s3.get_object(Bucket=\"maniks-chb-mit\", Key='chb01/chb01-summary.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mprint\u001b[39m(torch\u001b[39m.\u001b[39m__version__)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "ssh-keygen -t ed25519 -C \"sethi.manik@gmail.com\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Ictal Ranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Files\n",
    "summs = []\n",
    "for patient_num in subject_list:\n",
    "    summs.append(f\"chb{patient_num:02d}/chb{patient_num:02d}-summary.txt\")\n",
    "\n",
    "# Auxillary Function\n",
    "def get_summary_file_object(bucket_name, key):\n",
    "    obj = s3.get_object(Bucket=bucket_name, Key=key)\n",
    "    content = obj[\"Body\"].read().decode(\"utf-8\")\n",
    "    return io.StringIO(content)\n",
    "\n",
    "all_ranges = {}\n",
    "\n",
    "# Get the file-like object from S3\n",
    "for s3_key in summs:\n",
    "    summary_file_obj = get_summary_file_object(bucket_name, s3_key)\n",
    "    subject_ranges = extract_interictal_preictal(summary_file_obj)\n",
    "    all_ranges[s3_key[0:5]] = subject_ranges\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Preictal': [], 'Interictal': [(0.0, 3600.0)]}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_ranges[\"chb01\"][\"chb01_01.edf\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing subject: 1\n",
      "maniks-chb-mit/chb01/chb01_01.edf\n",
      "Epoch 1 from file tmpr7tsr874.edf processed, label Interictal, 22 channels\n",
      "maniks-chb-mit/chb01/chb01_02.edf\n",
      "Epoch 1 from file tmphroavcyx.edf processed, label Preictal, 22 channels\n",
      "Epoch 2 from file tmphroavcyx.edf processed, label Interictal, 22 channels\n",
      "maniks-chb-mit/chb01/chb01_03.edf\n",
      "Epoch 1 from file tmpycx0am21.edf processed, label Preictal, 22 channels\n",
      "maniks-chb-mit/chb01/chb01_04.edf\n",
      "maniks-chb-mit/chb01/chb01_05.edf\n",
      "maniks-chb-mit/chb01/chb01_06.edf\n",
      "maniks-chb-mit/chb01/chb01_07.edf\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[55], line 34\u001b[0m\n\u001b[1;32m     23\u001b[0m pipe \u001b[39m=\u001b[39m Pipeline()\n\u001b[1;32m     24\u001b[0m pipe\u001b[39m.\u001b[39mCONFIG(\n\u001b[1;32m     25\u001b[0m     fname\u001b[39m=\u001b[39mtmp_filename,\n\u001b[1;32m     26\u001b[0m     fs\u001b[39m=\u001b[39mconfig[\u001b[39m\"\u001b[39m\u001b[39mfs\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     31\u001b[0m     ranges_dict\u001b[39m=\u001b[39mranges[baka]\n\u001b[1;32m     32\u001b[0m )\n\u001b[0;32m---> 34\u001b[0m combined_epochs, epoch_labels \u001b[39m=\u001b[39m pipe\u001b[39m.\u001b[39;49mrun_pipeline()\n\u001b[1;32m     36\u001b[0m \u001b[39m# ***** The change is here: Instead of looping over epochs and replicating labels, \u001b[39;00m\n\u001b[1;32m     37\u001b[0m \u001b[39m# simply extend the global lists with the epochs and labels returned by the pipeline.\u001b[39;00m\n\u001b[1;32m     38\u001b[0m all_time_bins\u001b[39m.\u001b[39mextend(combined_epochs)\n",
      "File \u001b[0;32m~/Code/TGCNN/pipeline.py:175\u001b[0m, in \u001b[0;36mPipeline.run_pipeline\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[39mdef\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mrun_pipeline\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m--> 175\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mread_fname()\n\u001b[1;32m    176\u001b[0m     \u001b[39m# print(\"read file\")\u001b[39;00m\n\u001b[1;32m    177\u001b[0m     combined_epochs, labels \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcreate_epochs()\n",
      "File \u001b[0;32m~/Code/TGCNN/pipeline.py:41\u001b[0m, in \u001b[0;36mPipeline.read_fname\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[39mdef\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mread_fname\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m     40\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mraw \u001b[39m=\u001b[39m read_raw_edf(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfname, preload\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, verbose\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mERROR\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m---> 41\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mraw\u001b[39m.\u001b[39;49mfilter(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mf_low, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mf_high, fir_design\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mfirwin\u001b[39;49m\u001b[39m\"\u001b[39;49m, skip_by_annotation\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39medge\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m     43\u001b[0m     \u001b[39m# Define the gold-standard channel order (only the channels you want to keep)\u001b[39;00m\n\u001b[1;32m     44\u001b[0m     gold_standard \u001b[39m=\u001b[39m [\n\u001b[1;32m     45\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFP1-F7\u001b[39m\u001b[39m\"\u001b[39m, \n\u001b[1;32m     46\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mF7-T7\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFT10-T8\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     67\u001b[0m     ]\n",
      "File \u001b[0;32m~/Code/TGCNN/venv/lib/python3.11/site-packages/mne/io/base.py:1174\u001b[0m, in \u001b[0;36mBaseRaw.filter\u001b[0;34m(self, l_freq, h_freq, picks, filter_length, l_trans_bandwidth, h_trans_bandwidth, n_jobs, method, iir_params, phase, fir_window, fir_design, skip_by_annotation, pad, verbose)\u001b[0m\n\u001b[1;32m   1155\u001b[0m \u001b[39m@copy_doc\u001b[39m(FilterMixin\u001b[39m.\u001b[39mfilter)\n\u001b[1;32m   1156\u001b[0m \u001b[39mdef\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mfilter\u001b[39m(\n\u001b[1;32m   1157\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1172\u001b[0m     verbose\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   1173\u001b[0m ):\n\u001b[0;32m-> 1174\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mfilter(\n\u001b[1;32m   1175\u001b[0m         l_freq,\n\u001b[1;32m   1176\u001b[0m         h_freq,\n\u001b[1;32m   1177\u001b[0m         picks,\n\u001b[1;32m   1178\u001b[0m         filter_length,\n\u001b[1;32m   1179\u001b[0m         l_trans_bandwidth,\n\u001b[1;32m   1180\u001b[0m         h_trans_bandwidth,\n\u001b[1;32m   1181\u001b[0m         n_jobs\u001b[39m=\u001b[39;49mn_jobs,\n\u001b[1;32m   1182\u001b[0m         method\u001b[39m=\u001b[39;49mmethod,\n\u001b[1;32m   1183\u001b[0m         iir_params\u001b[39m=\u001b[39;49miir_params,\n\u001b[1;32m   1184\u001b[0m         phase\u001b[39m=\u001b[39;49mphase,\n\u001b[1;32m   1185\u001b[0m         fir_window\u001b[39m=\u001b[39;49mfir_window,\n\u001b[1;32m   1186\u001b[0m         fir_design\u001b[39m=\u001b[39;49mfir_design,\n\u001b[1;32m   1187\u001b[0m         skip_by_annotation\u001b[39m=\u001b[39;49mskip_by_annotation,\n\u001b[1;32m   1188\u001b[0m         pad\u001b[39m=\u001b[39;49mpad,\n\u001b[1;32m   1189\u001b[0m         verbose\u001b[39m=\u001b[39;49mverbose,\n\u001b[1;32m   1190\u001b[0m     )\n",
      "File \u001b[0;32m<decorator-gen-56>:12\u001b[0m, in \u001b[0;36mfilter\u001b[0;34m(self, l_freq, h_freq, picks, filter_length, l_trans_bandwidth, h_trans_bandwidth, n_jobs, method, iir_params, phase, fir_window, fir_design, skip_by_annotation, pad, verbose)\u001b[0m\n",
      "File \u001b[0;32m~/Code/TGCNN/venv/lib/python3.11/site-packages/mne/filter.py:2562\u001b[0m, in \u001b[0;36mFilterMixin.filter\u001b[0;34m(self, l_freq, h_freq, picks, filter_length, l_trans_bandwidth, h_trans_bandwidth, n_jobs, method, iir_params, phase, fir_window, fir_design, skip_by_annotation, pad, verbose)\u001b[0m\n\u001b[1;32m   2558\u001b[0m \u001b[39mfor\u001b[39;00m si, (start, stop) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(\u001b[39mzip\u001b[39m(onsets, ends)):\n\u001b[1;32m   2559\u001b[0m     \u001b[39m# Only output filter params once (for info level), and only warn\u001b[39;00m\n\u001b[1;32m   2560\u001b[0m     \u001b[39m# once about the length criterion (longest segment is too short)\u001b[39;00m\n\u001b[1;32m   2561\u001b[0m     use_verbose \u001b[39m=\u001b[39m verbose \u001b[39mif\u001b[39;00m si \u001b[39m==\u001b[39m max_idx \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39merror\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m-> 2562\u001b[0m     filter_data(\n\u001b[1;32m   2563\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_data[:, start:stop],\n\u001b[1;32m   2564\u001b[0m         s_freq,\n\u001b[1;32m   2565\u001b[0m         l_freq,\n\u001b[1;32m   2566\u001b[0m         h_freq,\n\u001b[1;32m   2567\u001b[0m         picks,\n\u001b[1;32m   2568\u001b[0m         filter_length,\n\u001b[1;32m   2569\u001b[0m         l_trans_bandwidth,\n\u001b[1;32m   2570\u001b[0m         h_trans_bandwidth,\n\u001b[1;32m   2571\u001b[0m         n_jobs,\n\u001b[1;32m   2572\u001b[0m         method,\n\u001b[1;32m   2573\u001b[0m         iir_params,\n\u001b[1;32m   2574\u001b[0m         copy\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m   2575\u001b[0m         phase\u001b[39m=\u001b[39;49mphase,\n\u001b[1;32m   2576\u001b[0m         fir_window\u001b[39m=\u001b[39;49mfir_window,\n\u001b[1;32m   2577\u001b[0m         fir_design\u001b[39m=\u001b[39;49mfir_design,\n\u001b[1;32m   2578\u001b[0m         pad\u001b[39m=\u001b[39;49mpad,\n\u001b[1;32m   2579\u001b[0m         verbose\u001b[39m=\u001b[39;49muse_verbose,\n\u001b[1;32m   2580\u001b[0m     )\n\u001b[1;32m   2581\u001b[0m \u001b[39m# update info if filter is applied to all data channels/vertices,\u001b[39;00m\n\u001b[1;32m   2582\u001b[0m \u001b[39m# and it's not a band-stop filter\u001b[39;00m\n\u001b[1;32m   2583\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m, _BaseSourceEstimate):\n",
      "File \u001b[0;32m<decorator-gen-51>:12\u001b[0m, in \u001b[0;36mfilter_data\u001b[0;34m(data, sfreq, l_freq, h_freq, picks, filter_length, l_trans_bandwidth, h_trans_bandwidth, n_jobs, method, iir_params, copy, phase, fir_window, fir_design, pad, verbose)\u001b[0m\n",
      "File \u001b[0;32m~/Code/TGCNN/venv/lib/python3.11/site-packages/mne/filter.py:1027\u001b[0m, in \u001b[0;36mfilter_data\u001b[0;34m(data, sfreq, l_freq, h_freq, picks, filter_length, l_trans_bandwidth, h_trans_bandwidth, n_jobs, method, iir_params, copy, phase, fir_window, fir_design, pad, verbose)\u001b[0m\n\u001b[1;32m   1012\u001b[0m filt \u001b[39m=\u001b[39m create_filter(\n\u001b[1;32m   1013\u001b[0m     data,\n\u001b[1;32m   1014\u001b[0m     sfreq,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     fir_design,\n\u001b[1;32m   1025\u001b[0m )\n\u001b[1;32m   1026\u001b[0m \u001b[39mif\u001b[39;00m method \u001b[39min\u001b[39;00m (\u001b[39m\"\u001b[39m\u001b[39mfir\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mfft\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m-> 1027\u001b[0m     data \u001b[39m=\u001b[39m _overlap_add_filter(data, filt, \u001b[39mNone\u001b[39;49;00m, phase, picks, n_jobs, copy, pad)\n\u001b[1;32m   1028\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1029\u001b[0m     data \u001b[39m=\u001b[39m _iir_filter(data, filt, picks, n_jobs, copy, phase)\n",
      "File \u001b[0;32m~/Code/TGCNN/venv/lib/python3.11/site-packages/mne/filter.py:346\u001b[0m, in \u001b[0;36m_overlap_add_filter\u001b[0;34m(x, h, n_fft, phase, picks, n_jobs, copy, pad)\u001b[0m\n\u001b[1;32m    342\u001b[0m         x[p] \u001b[39m=\u001b[39m _1d_overlap_filter(\n\u001b[1;32m    343\u001b[0m             x[p], \u001b[39mlen\u001b[39m(h), n_edge, phase, cuda_dict, pad, n_fft\n\u001b[1;32m    344\u001b[0m         )\n\u001b[1;32m    345\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 346\u001b[0m     data_new \u001b[39m=\u001b[39m parallel(\n\u001b[1;32m    347\u001b[0m         p_fun(x[p], \u001b[39mlen\u001b[39;49m(h), n_edge, phase, cuda_dict, pad, n_fft) \u001b[39mfor\u001b[39;49;00m p \u001b[39min\u001b[39;49;00m picks\n\u001b[1;32m    348\u001b[0m     )\n\u001b[1;32m    349\u001b[0m     \u001b[39mfor\u001b[39;00m pp, p \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(picks):\n\u001b[1;32m    350\u001b[0m         x[p] \u001b[39m=\u001b[39m data_new[pp]\n",
      "File \u001b[0;32m~/Code/TGCNN/venv/lib/python3.11/site-packages/joblib/parallel.py:1918\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1916\u001b[0m     output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_sequential_output(iterable)\n\u001b[1;32m   1917\u001b[0m     \u001b[39mnext\u001b[39m(output)\n\u001b[0;32m-> 1918\u001b[0m     \u001b[39mreturn\u001b[39;00m output \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreturn_generator \u001b[39melse\u001b[39;00m \u001b[39mlist\u001b[39m(output)\n\u001b[1;32m   1920\u001b[0m \u001b[39m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[1;32m   1921\u001b[0m \u001b[39m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[1;32m   1922\u001b[0m \u001b[39m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[1;32m   1923\u001b[0m \u001b[39m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[1;32m   1924\u001b[0m \u001b[39m# callback.\u001b[39;00m\n\u001b[1;32m   1925\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n",
      "File \u001b[0;32m~/Code/TGCNN/venv/lib/python3.11/site-packages/joblib/parallel.py:1847\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1845\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_dispatched_batches \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m   1846\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_dispatched_tasks \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m-> 1847\u001b[0m res \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1848\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_completed_tasks \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m   1849\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprint_progress()\n",
      "File \u001b[0;32m~/Code/TGCNN/venv/lib/python3.11/site-packages/mne/parallel.py:127\u001b[0m, in \u001b[0;36mparallel_func.<locals>.run_verbose\u001b[0;34m(verbose, *args, **kwargs)\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[39mdef\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mrun_verbose\u001b[39m(\u001b[39m*\u001b[39margs, verbose\u001b[39m=\u001b[39mlogger\u001b[39m.\u001b[39mlevel, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    126\u001b[0m     \u001b[39mwith\u001b[39;00m use_log_level(verbose\u001b[39m=\u001b[39mverbose):\n\u001b[0;32m--> 127\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Code/TGCNN/venv/lib/python3.11/site-packages/mne/filter.py:375\u001b[0m, in \u001b[0;36m_1d_overlap_filter\u001b[0;34m(x, n_h, n_edge, phase, cuda_dict, pad, n_fft)\u001b[0m\n\u001b[1;32m    372\u001b[0m seg \u001b[39m=\u001b[39m x_ext[start:stop]\n\u001b[1;32m    373\u001b[0m seg \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mconcatenate([seg, np\u001b[39m.\u001b[39mzeros(n_fft \u001b[39m-\u001b[39m \u001b[39mlen\u001b[39m(seg))])\n\u001b[0;32m--> 375\u001b[0m prod \u001b[39m=\u001b[39m _fft_multiply_repeated(seg, cuda_dict)\n\u001b[1;32m    377\u001b[0m start_filt \u001b[39m=\u001b[39m \u001b[39mmax\u001b[39m(\u001b[39m0\u001b[39m, start \u001b[39m-\u001b[39m shift)\n\u001b[1;32m    378\u001b[0m stop_filt \u001b[39m=\u001b[39m \u001b[39mmin\u001b[39m(start \u001b[39m-\u001b[39m shift \u001b[39m+\u001b[39m n_fft, n_x)\n",
      "File \u001b[0;32m~/Code/TGCNN/venv/lib/python3.11/site-packages/mne/cuda.py:215\u001b[0m, in \u001b[0;36m_fft_multiply_repeated\u001b[0;34m(x, cuda_dict)\u001b[0m\n\u001b[1;32m    196\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Do FFT multiplication by a filter function (possibly using CUDA).\u001b[39;00m\n\u001b[1;32m    197\u001b[0m \n\u001b[1;32m    198\u001b[0m \u001b[39mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    212\u001b[0m \u001b[39m    Filtered version of x.\u001b[39;00m\n\u001b[1;32m    213\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    214\u001b[0m \u001b[39m# do the fourier-domain operations\u001b[39;00m\n\u001b[0;32m--> 215\u001b[0m x_fft \u001b[39m=\u001b[39m cuda_dict[\u001b[39m\"\u001b[39;49m\u001b[39mrfft\u001b[39;49m\u001b[39m\"\u001b[39;49m](x, cuda_dict[\u001b[39m\"\u001b[39;49m\u001b[39mn_fft\u001b[39;49m\u001b[39m\"\u001b[39;49m])\n\u001b[1;32m    216\u001b[0m x_fft \u001b[39m*\u001b[39m\u001b[39m=\u001b[39m cuda_dict[\u001b[39m\"\u001b[39m\u001b[39mh_fft\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m    217\u001b[0m x \u001b[39m=\u001b[39m cuda_dict[\u001b[39m\"\u001b[39m\u001b[39mirfft\u001b[39m\u001b[39m\"\u001b[39m](x_fft, cuda_dict[\u001b[39m\"\u001b[39m\u001b[39mn_fft\u001b[39m\u001b[39m\"\u001b[39m])\n",
      "File \u001b[0;32m~/Code/TGCNN/venv/lib/python3.11/site-packages/scipy/fft/_backend.py:28\u001b[0m, in \u001b[0;36m_ScipyBackend.__ua_function__\u001b[0;34m(method, args, kwargs)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[39mif\u001b[39;00m fn \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     27\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mNotImplemented\u001b[39m\n\u001b[0;32m---> 28\u001b[0m \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Code/TGCNN/venv/lib/python3.11/site-packages/scipy/fft/_basic_backend.py:91\u001b[0m, in \u001b[0;36mrfft\u001b[0;34m(x, n, axis, norm, overwrite_x, workers, plan)\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[39mdef\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mrfft\u001b[39m(x, n\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, axis\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, norm\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[1;32m     90\u001b[0m          overwrite_x\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, workers\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m, plan\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m---> 91\u001b[0m     \u001b[39mreturn\u001b[39;00m _execute_1D(\u001b[39m'\u001b[39;49m\u001b[39mrfft\u001b[39;49m\u001b[39m'\u001b[39;49m, _pocketfft\u001b[39m.\u001b[39;49mrfft, x, n\u001b[39m=\u001b[39;49mn, axis\u001b[39m=\u001b[39;49maxis, norm\u001b[39m=\u001b[39;49mnorm,\n\u001b[1;32m     92\u001b[0m                        overwrite_x\u001b[39m=\u001b[39;49moverwrite_x, workers\u001b[39m=\u001b[39;49mworkers, plan\u001b[39m=\u001b[39;49mplan)\n",
      "File \u001b[0;32m~/Code/TGCNN/venv/lib/python3.11/site-packages/scipy/fft/_basic_backend.py:32\u001b[0m, in \u001b[0;36m_execute_1D\u001b[0;34m(func_str, pocketfft_func, x, n, axis, norm, overwrite_x, workers, plan)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[39mif\u001b[39;00m is_numpy(xp):\n\u001b[1;32m     31\u001b[0m     x \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39masarray(x)\n\u001b[0;32m---> 32\u001b[0m     \u001b[39mreturn\u001b[39;00m pocketfft_func(x, n\u001b[39m=\u001b[39;49mn, axis\u001b[39m=\u001b[39;49maxis, norm\u001b[39m=\u001b[39;49mnorm,\n\u001b[1;32m     33\u001b[0m                           overwrite_x\u001b[39m=\u001b[39;49moverwrite_x, workers\u001b[39m=\u001b[39;49mworkers, plan\u001b[39m=\u001b[39;49mplan)\n\u001b[1;32m     35\u001b[0m norm \u001b[39m=\u001b[39m _validate_fft_args(workers, plan, norm)\n\u001b[1;32m     36\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(xp, \u001b[39m'\u001b[39m\u001b[39mfft\u001b[39m\u001b[39m'\u001b[39m):\n",
      "File \u001b[0;32m~/Code/TGCNN/venv/lib/python3.11/site-packages/scipy/fft/_pocketfft/basic.py:61\u001b[0m, in \u001b[0;36mr2c\u001b[0;34m(forward, x, n, axis, norm, overwrite_x, workers, plan)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39minvalid number of data points (\u001b[39m\u001b[39m{\u001b[39;00mtmp\u001b[39m.\u001b[39mshape[axis]\u001b[39m}\u001b[39;00m\u001b[39m) specified\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     60\u001b[0m \u001b[39m# Note: overwrite_x is not utilised\u001b[39;00m\n\u001b[0;32m---> 61\u001b[0m \u001b[39mreturn\u001b[39;00m pfft\u001b[39m.\u001b[39;49mr2c(tmp, (axis,), forward, norm, \u001b[39mNone\u001b[39;49;00m, workers)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "all_time_bins = []  # Will accumulate STFT outputs of shape (22, 5, t_i)\n",
    "all_labels = []   \n",
    "\n",
    "for subj in subject_list:\n",
    "    print(f\"Processing subject: {subj}\")\n",
    "    pattern = f\"s3://maniks-chb-mit/chb{subj:02d}/*.edf\"\n",
    "    ranges = all_ranges[f\"chb{subj:02d}\"]\n",
    "    edf_files = fs.glob(pattern)\n",
    "    \n",
    "    for edf_path in edf_files:\n",
    "        # Create a temporary file for the current EDF file\n",
    "        print(edf_path)\n",
    "\n",
    "        file_num = edf_path.split('/')[2]\n",
    "\n",
    "        with tempfile.NamedTemporaryFile(delete=False, suffix=\".edf\") as tmp_file:\n",
    "            tmp_filename = tmp_file.name\n",
    "\n",
    "        # Download the EDF file from S3 to the temporary file\n",
    "        fs.get(edf_path, tmp_filename)\n",
    "\n",
    "        # Run the file through our pipeline\n",
    "        pipe = Pipeline()\n",
    "        pipe.CONFIG(\n",
    "            fname=tmp_filename,\n",
    "            fs=config[\"fs\"],\n",
    "            window_size=config[\"window_size\"],\n",
    "            overlap=config[\"overlap\"],\n",
    "            f_low=config[\"f_low\"],\n",
    "            f_high=config[\"f_high\"],\n",
    "            ranges_dict=ranges[file_num]\n",
    "        )\n",
    "        \n",
    "        combined_epochs, epoch_labels = pipe.run_pipeline()\n",
    "        \n",
    "        # ***** The change is here: Instead of looping over epochs and replicating labels, \n",
    "        # simply extend the global lists with the epochs and labels returned by the pipeline.\n",
    "        all_time_bins.extend(combined_epochs)\n",
    "        all_labels.extend(epoch_labels)\n",
    "\n",
    "        # Clean up: remove the temporary file\n",
    "        os.remove(tmp_filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate along the time axis: bake\n",
    "if all_time_bins:\n",
    "    X = np.concatenate(all_time_bins, axis=-1)  # Final shape: (22, 5, total_time_bins)\n",
    "else:\n",
    "    X = None\n",
    "\n",
    "y = np.array(all_labels)  # y has length equal to the total number of labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapping dictionary\n",
    "mapping = {\n",
    "    \"Interictal\": 0,\n",
    "    \"Preictal\": 1\n",
    "}\n",
    "\n",
    "# vectorize the mapping\n",
    "map_func = np.vectorize(mapping.get)\n",
    "numeric_labels = map_func(copy_y)\n",
    "\n",
    "print(numeric_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = tf.tensor(X)\n",
    "y1 = tf.tensor(numeric_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x2 = x1.permute(2,0,1)\n",
    "dataset = TensorDataset(x2, y1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
